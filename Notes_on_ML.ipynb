{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Notes_on_ML.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPjHDv30FmDPJryTOooaDPV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joniald/Colaboratory/blob/main/Notes_on_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGVTrFlyk5p1"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWsdbQphLbCa"
      },
      "source": [
        "## Cross-validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwXF-vQjKLw4"
      },
      "source": [
        "Scikit-Learn’s K-fold cross-validation feature. The following code randomly splits the training set into 10 distinct subsets called folds, then it\n",
        "trains and evaluates the model 10 times, picking a different fold for evaluation every time and training on the other 9 folds. \n",
        "The result is an array containing the 10 evaluation scores:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVUGJHFzLZg4"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16cRSwMqLHI3"
      },
      "source": [
        "from sklearn.model_selection import cross_val_predict"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6R665d1LK-w"
      },
      "source": [
        "Just like the cross_val_score() function, cross_val_predict() performs K-fold\n",
        "cross-validation, but instead of returning the evaluation scores, it returns the predictions\n",
        "made on each test fold."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVCOZ6jXcbin"
      },
      "source": [
        "## Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Q6AakZ2cM1r"
      },
      "source": [
        "The accuracy is the proportion of correct predictions (both true positives and true negatives) among the total number of cases examined.\n",
        "\n",
        "Accuracy is generally not the preferred performance measure for classifiers, especially when you are dealing with skewed datasets \n",
        "(i.e., when some classes are much more frequent than others)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "av6IMRVhbqd8"
      },
      "source": [
        "$accuracy = \\frac{TP+FN}{TP+FN+FP+TN}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0-3qO8Mgpmb"
      },
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iM43tLrpeE7I"
      },
      "source": [
        "## Persition, Recall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDjum1sPXA2v"
      },
      "source": [
        "True positives are data points classified as positive by the model that actually are positive (meaning they are correct). (TP)\n",
        "False negatives are data points the model identifies as negative that actually are positive (incorrect). (FN)\n",
        "False positives are cases the model incorrectly labels as positive that are actually negative. (FP)\n",
        "True negative cases the model incorrectly labels as negative that are actually positive. (TN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0vEzMVccKIT"
      },
      "source": [
        "$persition = \\frac{TP}{TP+FP}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYXUlwz4cuSg"
      },
      "source": [
        "$recall = \\frac{TP}{TP+FN}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8PZGl1Me6Q7"
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5xNS1nIhYzi"
      },
      "source": [
        "## F1-score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hU9lZuLAhfAX"
      },
      "source": [
        "The F1 score favors classifiers that have similar precision and recall. This is not always \n",
        "what you want: in some contexts you mostly care about precision, and in other contexts\n",
        "you really care about recall. For example, if you trained a classifier to detect videos\n",
        "that are safe for kids, you would probably prefer a classifier that rejects many\n",
        "good videos (low recall) but keeps only safe ones (high precision), rather than a classifier\n",
        "that has a much higher recall but lets a few really bad videos show up in your\n",
        "product (in such cases, you may even want to add a human pipeline to check the classifier’s\n",
        "video selection). On the other hand, suppose you train a classifier to detect\n",
        "shoplifters in surveillance images: it is probably fine if your classifier has only 30%\n",
        "precision as long as it has 99% recall (sure, the security guards will get a few false\n",
        "alerts, but almost all shoplifters will get caught)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAFnRYUpdTAm"
      },
      "source": [
        "$F1 = 2*\\frac{persition*recall}{persition+recall}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfQDcHLHfIxD"
      },
      "source": [
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vYQSTkZd9Xx"
      },
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4ve7Qh9doqF"
      },
      "source": [
        "A much better way to evaluate the performance of a classifier is to look at the confusion\n",
        "matrix. The general idea is to count the number of times instances of class A are\n",
        "classified as class B."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2QDzMWXeI9A"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irhbN9vXfbtj",
        "outputId": "5e2d8338-88c0-49a8-d592-03d65069105c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Sklearn\n",
        "\n",
        "y_train = [1,1,0,0,1,0,0,1,1,1,0,0,1,0,1,0,1,0,0,0,0]\n",
        "y_predict = [0,1,0,1,1,1,0,1,0,1,0,0,0,1,0,0,1,0,1,0,1]\n",
        "\n",
        "print(accuracy_score(y_train, y_predict))\n",
        "print(precision_score(y_train, y_predict))\n",
        "print(recall_score(y_train, y_predict))\n",
        "print(f1_score(y_train, y_predict))\n",
        "print(confusion_matrix(y_train, y_predict))\n",
        "             "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5714285714285714\n",
            "0.5\n",
            "0.5555555555555556\n",
            "0.5263157894736842\n",
            "[[7 5]\n",
            " [4 5]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02t63129lKgR",
        "outputId": "7cd126b7-6a76-4f68-b023-aa1b4cf161ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# TensorFlow\n",
        "\n",
        "y_train = [1,1,0,0,1,0,0,1,1,1,0,0,1,0,1,0,1,0,0,0,0]\n",
        "y_predict = [0,1,0,1,1,1,0,1,0,1,0,0,0,1,0,0,1,0,1,0,1]\n",
        "\n",
        "m = tf.keras.metrics.Precision()\n",
        "m.update_state(y_train, y_predict)\n",
        "m.result().numpy()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__zZ70GiPldH"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Imrx1kPuPrap"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0G7z_S1RAXu"
      },
      "source": [
        "from sklearn.linear_model import SGDRegressor"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73sMWfwPPvYr",
        "outputId": "30f962bb-cf2b-446b-cb84-df74b43c5e7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "reg = LinearRegression()\n",
        "reg.fit([[0, 0], [1, 1], [2, 2]], [0, 1, 2])\n",
        "reg.predict([[3,3]])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3.])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vLCISLktdR5"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5lAIIqn-EXS"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwoX_i7b-K6k"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neighbors import KNeighborsRegressor"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qu8xsJvet-8x"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "regr = RandomForestRegressor(max_depth=2, random_state=0)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9D8Ko0yLjlMv",
        "outputId": "4ffcb12b-b9b8-4ae4-c120-e2c01051c0e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "svm_model = SVC()\n",
        "svm_model.fit([[0, 0], [1, 1], [2, 2]], [0, 1, 2])\n",
        "svm_model.predict([[3,3]])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvIS1pjQuvG7"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import DecisionTreeRegressor"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2JnqmjTjNch"
      },
      "source": [
        "## Multiclass Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXuE0wRSjPlu"
      },
      "source": [
        "SGD classifiers, Random Forest classifiers, and naive Bayes classifiers are capable of handling multiple classes natively.\n",
        "Logistic Regression or Support Vector Machine classifiers are strictly binary classifiers. \n",
        "However, there are various strategies that you can use to perform multiclass classification with multiple binary classifiers.\n",
        "\n",
        "The one-versus-the-rest (OvR) strategy.\n",
        "The one-versus-one (OvO) strategy\n",
        "\n",
        "Scikit-Learn detects when you try to use a binary classification algorithm for a multiclass classification task, and it automatically runs OvR or OvO, depending on the algorithm."
      ]
    }
  ]
}