{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Notes_on_ML.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOM7U96QFtv6hitJ8vE5Wo3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joniald/Colaboratory/blob/main/Notes_on_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWsdbQphLbCa"
      },
      "source": [
        "## Cross-validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwXF-vQjKLw4"
      },
      "source": [
        "Scikit-Learnâ€™s K-fold cross-validation feature. The following code randomly splits the training set into 10 distinct subsets called folds, then it\n",
        "trains and evaluates the model 10 times, picking a different fold for evaluation every time and training on the other 9 folds. \n",
        "The result is an array containing the 10 evaluation scores:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVUGJHFzLZg4"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVCOZ6jXcbin"
      },
      "source": [
        "## Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Q6AakZ2cM1r"
      },
      "source": [
        "The accuracy is the proportion of correct predictions (both true positives and true negatives) among the total number of cases examined.\n",
        "\n",
        "Accuracy is generally not the preferred performance measure for classifiers, especially when you are dealing with skewed datasets \n",
        "(i.e., when some classes are much more frequent than others)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "av6IMRVhbqd8"
      },
      "source": [
        "$accuracy = \\frac{TP+FN}{TP+FN+FP+TN}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iM43tLrpeE7I"
      },
      "source": [
        "## Persition, Recall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDjum1sPXA2v"
      },
      "source": [
        "True positives are data points classified as positive by the model that actually are positive (meaning they are correct). (TP)\n",
        "False negatives are data points the model identifies as negative that actually are positive (incorrect). (FN)\n",
        "False positives are cases the model incorrectly labels as positive that are actually negative. (FP)\n",
        "True negative cases the model incorrectly labels as negative that are actually positive. (TN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0vEzMVccKIT"
      },
      "source": [
        "$persition = \\frac{TP}{TP+FP}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYXUlwz4cuSg"
      },
      "source": [
        "$recall = \\frac{TP}{TP+FN}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAFnRYUpdTAm"
      },
      "source": [
        "$F1 = 2*\\frac{persition*recall}{persition+recall}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vYQSTkZd9Xx"
      },
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4ve7Qh9doqF"
      },
      "source": [
        "A much better way to evaluate the performance of a classifier is to look at the confusion\n",
        "matrix. The general idea is to count the number of times instances of class A are\n",
        "classified as class B."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "m2QDzMWXeI9A"
      },
      "source": [
        "from sklearn.metrics import "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}